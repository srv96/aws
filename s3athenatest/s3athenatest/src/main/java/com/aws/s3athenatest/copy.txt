
import org.apache.avro.Schema;
import org.apache.avro.file.DataFileWriter;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericDatumWriter;
import org.apache.avro.io.DatumWriter;
import org.apache.avro.io.EncoderFactory;
import org.apache.avro.io.JsonEncoder;

import java.io.*;
import java.util.List;

public class AvroConverter {

    public static InputStream convertListToAvroInputStream(List<byte[]> dataList, String avroSchema) throws IOException {
        Schema schema = new Schema.Parser().parse(avroSchema);
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();

        DatumWriter<GenericData.Record> datumWriter = new GenericDatumWriter<>(schema);
        JsonEncoder encoder = EncoderFactory.get().jsonEncoder(schema, outputStream);

        try (DataFileWriter<GenericData.Record> dataFileWriter = new DataFileWriter<>(datumWriter)) {
            dataFileWriter.create(schema, outputStream);
            for (byte[] data : dataList) {
                GenericData.Record record = new GenericData.Record(schema);
                record.put("data", data); // Assuming the Avro schema has a field "data" of type bytes
                dataFileWriter.append(record);
            }
        }

        return new ByteArrayInputStream(outputStream.toByteArray());
    }

    // Example usage
    public static void main(String[] args) {
        List<byte[]> dataList = Arrays.asList("Hello".getBytes(), "World".getBytes());
        String avroSchema = "{\"type\":\"record\",\"name\":\"DataRecord\",\"fields\":[{\"name\":\"data\",\"type\":\"bytes\"}]}";

        try {
            InputStream avroInputStream = convertListToAvroInputStream(dataList, avroSchema);
            // Use the avroInputStream as needed
            // For example, you can write it to a file or send it over a network.
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
