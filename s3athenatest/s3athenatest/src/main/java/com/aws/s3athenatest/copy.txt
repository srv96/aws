
import org.apache.arrow.memory.BufferAllocator;
import org.apache.arrow.memory.RootAllocator;
import org.apache.arrow.vector.*;
import org.apache.arrow.vector.ipc.ArrowFileWriter;
import org.apache.arrow.vector.types.pojo.*;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.List;

public class ParquetConverter {

    public static InputStream convertListToParquetInputStream(List<String> dataList, Schema schema) throws IOException {
        try (BufferAllocator allocator = new RootAllocator()) {
            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
            try (VectorSchemaRoot root = VectorSchemaRoot.create(schema, allocator);
                 ArrowFileWriter writer = new ArrowFileWriter(root, null, Channels.newChannel(outputStream))) {

                List<FieldVector> vectors = root.getFieldVectors();
                for (FieldVector vector : vectors) {
                    vector.allocateNew();
                }

                for (String data : dataList) {
                    for (int i = 0; i < vectors.size(); i++) {
                        String value = (String) data; // Assuming that the dataList contains strings
                        FieldVector vector = vectors.get(i);
                        if (vector instanceof VarCharVector) {
                            VarCharVector charVector = (VarCharVector) vector;
                            byte[] bytes = value.getBytes();
                            charVector.setSafe(0, bytes);
                            charVector.setValueCount(1);
                        } else {
                            // Handle other types as per your schema requirements
                        }
                    }
                    root.setRowCount(1);
                    writer.writeBatch();
                }

                writer.end();
            }

            return new ByteArrayInputStream(outputStream.toByteArray());
        }
    }

    // Example usage
    public static void main(String[] args) {
        List<String> dataList = Arrays.asList("String 1", "String 2", "String 3");
        Field field = new Field("data", FieldType.nullable(new ArrowType.Utf8()), null);
        Schema schema = new Schema(List.of(field));

        try {
            InputStream parquetInputStream = convertListToParquetInputStream(dataList, schema);
            // Use the parquetInputStream as needed
            // For example, you can write it to a file or send it over a network.
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
